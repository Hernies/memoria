\chapter{Fundamentos y Panorama Actual}
\label{ch:fundamentos}
Capítulo dedicado a describir los fundamentos y el panorama actual del trabajo. 

\section{Monitorización de Carga No Intrusiva}
\label{se:MonitorizaciondeCargaNoIntrusiva}
Este concepto fue inventado por George W. Hart, Ed Kern y Fred Schweppe en el Instituto Tecnológico de Massachussets, en los años ochenta \autocite{192069}. Fundados por el Electric Power Research Institute, podemos encontrar el proceso básico descrito en la patente estadounidense 4,858,141.

Una breve bibliografía de George W. Hart: Actualmente ejerce como escultor desde 2017. Tiene esculturas en exposición en Berkeley, Princeton, Cambridge, Duke, Brown... Cofundó el Museo de las Matemáticas y se ha retirado recientemente, trabajó en ciencia computacional, matemáticas, educación e investigación.

\subsection{Modelado y Teoría}
\label{sse:ModeladoyTeoria}
La técnica, descrita por Hart, Kern y Schweppe en su publicación modela los consumos en lo que nombran como "Modelo Total de Carga". El modelo total de carga depende de que dispositivos estén encendidos en un momento dado. Por lo que definen un 'proceso de cambio'
$a(t)$ donde a es un dispositivo de consumo eléctrico en un instante de tiempo $t$. Suponiendo $n$ dispositivos,$a(t)$ será un vector Booleano de $n$ componentes:

$$
a_i(t)=
	\left\{
	\begin{array}{l}
	1,\text{si dispositivo } i \text{ encendido en } t\\
	0, \text{si dispositivo } i \text{ apagado en } t
	\end{array}
	\right.
$$

Continúan modelando el sistema de potencia total $P(t)$ para un sistema de corriente alterna como el estado de un dispositivo $a_i$ por su consumo $P_i$ con un pequeño ruido o error $e$
$$
P(t)=\sum_{i=1}^{n} a_i(t)P_i+e(t)
$$

El criterio para determinar el valor de cada una de los dispositivos es entonces:
$$
\hat{a}(t) = \underset{a}{\text{arg min}} \left| P(t) - \sum_{i=1}^{n} a_i(t)P_i \right|
$$

Esto nos lleva a un problema computacionalmente imposible de resolver salvo mediante la fuerza bruta\autocite[4]{192069} y poco margen de mejora en el modelado para simplificar su resolución. De manera resumida, el problema trata en encontrar el número de dispositivos y el consumo de cada uno. 
Este es un problema que se beneficia de hacer uso de modelos heurísticos.

El concepto de NILM desde su introducción ha sido el método preferido por ingenieros e investigadores para la disgregación de consumo desde su introducción, debido a sus ventajas económicas y prácticas.\autocite[pág. 2, pár. 4]{Nalmpantis2019}

En cuanto al origen de este método, se buscó categorizar los dispositivos dentro de tres grandes grupos, para poder estructurar los diferentes dispositivos y generalizar el modelado de dispositivos específicos. 
Estos grupos son: 

\begin{enumerate}
\item \textbf{Señales de estados fijos} Siguen la arquitecturea de una máquina de estados finita, las transiciones entre estados son consumos exactos, al igual que los estados
\item \textbf{Señales transitorias} Esto son señales que no se encuentran en un espacio discreto que permita modelar su comportamiento como una máquina de estados. Un ejemplo podría ser un calefactor automático, que regula su generación de calor en función de la diferencia de la temperatura ambiente y la temperatura objetivo.
\item \textbf{Otras} Señales que no pueden categorizarse en ninguno de los dos casos anteriores. Por ejemplo, los cambios de dirección del motor de una lavadora en el proceso de lavado. 
\end{enumerate}

Cabe mencionar que los propios investigadores reconocieron que en el futuro los dispositivos eléctricos que siguiesen un diseño de máquinas de estados perderían precedencia. Ya que habría más 'dispositivos inteligentes'. Actualmente, una calefacción programable o un aire acondicionado programable están al alcance de cualquiera.
En 2021, en España el 50\% de las viviendas en alquiler constan de aire acondicionado\autocite{idealista2021}. 

Y esto es sólo un dispositivo. Habrá cientos de modelos de cada dispositivo, decenas de marcas, cada dispositivo con sus características específicas. 
Un modelado exhaustivo sería prácticamente imposible de crear y mantener, ya que sólo para el mercado doméstico hay una cantidad desorbitante de dispositivos, combinaciones de dispositivos, ect.

\subsubsection{Un ejemplo de sistema NILM}
Un sistema NILM consta de las siguientes partes: Una fuente de datos. Un dispositivo de recogida de datos. El modelo predictivo. Y el sistema de consulta de datos.
\todo[inline]{Diagrama de sistema NILM aquí podrá verse un diagrama que ejemplifique lo descrito} 

Debido a estos argumentos, la investigación de la monitorización no intrusiva se inclinó a los modelos heurísiticos. De los que voy a destacar los Modelos Ocultos de Markov, el Sparse Coding y finalmente las Redes Neuronales. Siendo estas últimas el foco principal del trabajo, y de este capítulo. 

\subsection{Modelos Ocultos de Markov}
Si se sabe la teoría detrás de una cadena de markov, los modelos de Markov Ocultos resultan una dirección intuitiva a tomar, ya que estos representan la probabilidad de transición de un estado a otro. En esta subsección daremos una breve introducción a la teoría detrás de este modelo probabilístico.
\subsubsection{La Cadena de Markov}
Formalmente, una cadena de Markov se representa por los siguientes componentes:
\begin{center}
    \begin{itemize}
        \item Un conjunto $Q$ de $N$ estados: $$Q = q_1q_2...q_n$$
        \item Una matriz de probabilidad de transición $A$ donde para cada $a_{ij}$ representando la probabilidad de transicionar desde el estado $j$ al estado $i$. $$A=a_{11}a_{12}...a_{N1}...a_{NN}$$ 
        {\footnotesize Cumpliendo $A$ la propiedad: $\sum_{j=1}^n a_{ij} \forall{i}$}
        \item Una distribución de probabilidad inicial $\pi$ sobre los est
        ados. Siendo $\pi_i$ la probabilidad de que la cadena de Markov comience en el estado $i$. $$\pi=\pi_1,\pi_2, ...,\pi_N$$ 
        {\footnotesize Si un estado $j$ tuviera $\pi_j=0$ no podría ser un estado inicial (teniendo probabilidad $0$).\linebreak Además,$\pi$ debe cumplir $\sum_{i=1}^N \pi_i = 1$}
    \end{itemize} 
    \autocite{markovStandford}
\end{center}


\subsubsection{Identificando Datos Ocultos Con Cadenas de Markov}
Una cadena de Markov resulta útil cuando tenemos que modelar un comportamiento en base a una secuencia de eventos observables. 
Estos eventos observables son elementos conocidos, pero la secuencia de estados del modelo para esos eventos observables son desconocidos. 

El problema, como en NILM, es que los estados no son directamente observables. Estan \textit{ocultos} y por tanto debemos ajustar la cadena para incluir una secuencia de posibles similitudes observadas. 

Continuando la explicación de \autocite{markovStandford} en la subsección anterior:
\begin{center}
    \begin{itemize}
        \item Para un elemento $i$ se expresa como $b_i(o)$ donde $o$ es derivado de un conjunto de posibles valores observables $V$.

        \item Dado: $$Q = q_1q_2...q_n$$ 
        \item Calculamos la probabilidad de una cadena de estados $S$ de longitud $T$ $$S=s_1,s_2,...,s_{T}$$
        \item Dado un conjunto de valores observados $$O=o_1,o_2,...,o_{T}$$ para ${T}$ observaciones.
\end{itemize} 
\end{center}

Resumiendo: dados una serie de eventos observables, podemos inferir los estados que causaron estos eventos observables. Calculando la probabilidad de una cadena de eventos observables dada la probabilidad de una cadena de estados del conjunto, para todas las posibles combinaciones de la cadena los estados del conjunto. 

Siendo la fórmula:
$$
\underset{O=o_1,o_2,...,o_{T}}{\text{arg max}} P (O=o_1,o_2,...,o_{T} | S=s_1,s_2,...,s_{T})
$$

Este es el modelado que nos permite inferir de manera probabilística (fórmulas en detalle podrán encontrarse en el \textbf{Anexo A})\todo{se añadirá el anexo para la entrega de la memoria final}

\subsubsection{Modelos Ocultos de Markov}
Explicadas brevemente las bases de los Modelos Ocultos de Markov, pasamos a la aplicación de este modelo estadístico en la disgregación de consumos.

Dado que un modelo de markov oculto infiere probabilísticamente una serie de estados, esto nos resulta útil para la disgregación de dispositivos. La forma de codificar diferentes estados de diferentes dispositivos se basa aumentando el ancho del modelo. Teniendo una matriz de estados $S_i^j$ donde $S$ es un conjunto de estados. Y las observaciones dependen de todos los estados en un momento dado. Podemos observar esto en el siguiente diagrama:
\todo[inline]{Dos diagramas, una HMM normal y una FHMM introducir cita de el OG}
Observando el diagrama b) no resulta muy complicado imaginar la utilidad de este modelo. Si cada cadena representa un dispositivo modelado en diferentes estados, resulta un diseño muy apropiado para NILM.
Los Modelos de Markov Ocultos se han tratado en la literatura como efectivos en comparación con otras técnicas de monitorización cuando el entrenamiento supervisado presenta una baja tasa de muestreo en el eje temporal de la obtención de datos \autocite{frenchHMMNILM}.
Otras ventajas que presenta es su bajo coste computacional en el entrenamiento. Pero el uso de este tipo de elementos lo vuelven altamente susceptible a máximos locales\autocite{NILMreview2017}.

En el caso de los Modelos Factoriales de Markov Ocultos (con siglas FHMM en inglés), presentan ciertas ventajas en comparación con los HMM \footnote{Hidden Markov Models, o en español los Modelos Ocultos de Markov}:
La complejidad y el coste computacional de los los algoritmos de aprendizaje e inferencia son menores para los HMM. Sin embargo, tanto FHMM como HMM presentan limitaciones al volumen máximo de dispositivos simultáneos, incluso en casos como \autocite{afmap2012} donde se propone un nuevo algoritmo no supervisado. El algoritmo desarrollado (AFMAP) no presenta los problemas de alta complejidad y máximos locales, pero requiere de etiquetación manual después de la disgregación. Y presenta bajo rendimiento para dispositivos electrónicos y de cocina \autocite[5]{NILMreview2017}.

\subsection{Sparse Coding}
\subsubsection{Breve Introducción}
\autocite{stanfordSparse}

\subsubsection{Aplicaciones}


\subsection{Redes Neuronales}
\subsubsection{Mapas de atención}
\subsubsection{Clasificadores de imágenes}
\subsubsection{Redes Recurrentes}


\section{Teoría detrás de la propuesta}
\subsection{Datasets para entrenamiento supervisado en NILM}
\subsection{CSPNet}     
\subsection{Codificación GAF} 
\subsection{Validación de Modelos: NILMTK}  

